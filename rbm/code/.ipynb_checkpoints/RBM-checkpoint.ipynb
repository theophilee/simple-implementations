{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import make_grid , save_image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RBM(nn.Module):\n",
    "    def __init__(self, n_vis=784, n_hid=500, k=5):\n",
    "        super(RBM, self).__init__()\n",
    "        self.W = nn.Parameter(torch.randn(n_hid, n_vis) * 1e-2)\n",
    "        self.v_bias = nn.Parameter(torch.zeros(n_vis))\n",
    "        self.h_bias = nn.Parameter(torch.zeros(n_hid))\n",
    "        self.k = k\n",
    "    \n",
    "    def sample_from(self, p):\n",
    "        return F.relu(torch.sign(p - Variable(torch.rand(p.size()))))\n",
    "    \n",
    "    def v_to_h(self, v):\n",
    "        p_h = F.sigmoid(F.linear(v, self.W, self.h_bias))\n",
    "        sample_h = self.sample_from(p_h)\n",
    "        return p_h, sample_h\n",
    "    \n",
    "    def h_to_v(self, h):\n",
    "        p_v = F.sigmoid(F.linear(h, self.W.t(), self.v_bias))\n",
    "        sample_v = self.sample_from(p_v)\n",
    "        return p_v, sample_v\n",
    "        \n",
    "    def forward(self, v):\n",
    "        _, h_ = self.v_to_h(v)\n",
    "        for _ in range(self.k):\n",
    "            _, v_ = self.h_to_v(h_)\n",
    "            _, h_ = self.v_to_h(v_)\n",
    "        return v_\n",
    "    \n",
    "    def free_energy(self, v):\n",
    "        term1 = v.mv(self.v_bias)\n",
    "        term2 = F.linear(v, self.W, self.h_bias).exp().add(1).log().sum(1)\n",
    "        return (-term1 - term2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=True, download=True,\n",
    "                   transform=transforms.Compose([transforms.ToTensor()])),\n",
    "    batch_size=batch_size)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=False, \n",
    "                   transform=transforms.Compose([transforms.ToTensor()])),\n",
    "    batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rbm = RBM(k=1)\n",
    "train_op = optim.SGD(rbm.parameters(), 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss = -8.42941292313\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "for epoch in range(n_epochs):\n",
    "    losses = []\n",
    "    \n",
    "    for _, (data, target) in enumerate(train_loader):\n",
    "        v = Variable(data.view(-1, 784)) # Floats in [0, 1] \n",
    "        v_data = v.bernoulli() # Input sampled from Bernoulli\n",
    "        v_model = rbm(v_data) # Output after k epochs of Gibbs sampling\n",
    "        loss = rbm.free_energy(v_data) - rbm.free_energy(v_model)\n",
    "        losses.append(loss.data[0])\n",
    "        train_op.zero_grad()\n",
    "        loss.backward()\n",
    "        train_op.step()\n",
    "    \n",
    "    print \"Epoch {}, loss = {}\".format(epoch, np.mean(losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_and_save(file_name, img):\n",
    "    np_img = np.transpose(img.numpy(), (1, 2, 0))\n",
    "    f = \"./%s.png\" % file_name\n",
    "    plt.imshow(np_img)\n",
    "    plt.imsave(f, np_img)\n",
    "    plt.show()\n",
    "    \n",
    "show_and_save(\"real\", make_grid(v_data.view(32,1,28,28).data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "show_and_save(\"generated\", make_grid(v_model.view(32,1,28,28).data))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
